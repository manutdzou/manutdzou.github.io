---
layout: post
title: 使用记录
category: 技术
tags: 搭建环境
keywords: ubuntu
description:
---

# 服务器免密码登陆

首先本地和服务器端安装ssh
ssh-keygen在本地./ssh生成私钥和公钥
ssh-copy-id -i name.pub usr@ip将本地公钥拷贝到服务器端的.ssh里生成authorized_keys
至此实现了本地连服务器的免密码登陆

# ubuntu 截图 ctrl+alt+a

打开系统设置/键盘/Shortcuts/ 添加“截图” command gnome-screenshot -a 然后选中截图 按下ctrl+alt+a

# 清理ubuntu中孤立无用的软件包

安装Deborphan
sudo apt-get install deborphan
运行
deborphan
列出无用可删除的软件包
sudo orphaner

# ubuntu设代理

在bashrc或者profile中添加

```
export http_proxy="http://admin:admin@10.110.157.140:8080/"
export https_proxy="https://admin:admin@10.110.157.140:8080/"
export HTTP_PROXY="http://admin:admin@10.110.157.140:8080/"
export HTTPS_PROXY="https://admin:admin@10.110.157.140:8080/"
```

/etc/apt/apt.conf添加

```
Acquire::http::proxy "http://admin:admin@10.110.157.140:8080/";
Acquire::https::proxy "https://admin:admin@10.110.157.140:8080/";
Acquire::ftp::proxy "ftp://admin:admin@10.110.157.140:8080/";
Acquire::socks::proxy "socks://admin:admin@10.110.157.140:8080/";
```

# ubuntu下cuda7.5升级为cuda8
由于原来版本显卡驱动不支持cuda8需要先卸载原有显卡驱动

关闭桌面显示
sudo service lightdm stop
卸载显卡驱动
sudo apt-get remove --purge nvidia-*
安装cuda8包括里面的显卡驱动
开启桌面显示
sudo service lightdm start

# ubuntu远程拷贝文件和文件夹示例

```
scp myusername@university_computer:/home/myusername/file.odt homeusername@Felix:Desktop/file.odt
sudo scp -r /home/dlg/ssd_caffe bsl@172.25.85.12:/home/bsl
```

# 防止远程Linux主机自动断开SSH连接

我在使用ssh连接远程Linux主机时，如果长时间不操作，ssh会自动断开，只能重新登陆。

原因是：由于ssh的安全机制，如果10分钟没有任何操作，本次SSH会话会自动关闭。 

怎么防止远程Linux自动断开SSH连接

下面的操作是在本地ssh客户端上，不是远程主机。

编辑SSH配置文件：

```
vim ~/.ssh/config    # 当前登陆用户生效
```

添加：

```
Host *
 ServerAliveInterval 30
```

*号代表所有主机，你可以指定某个主机，如：

```
Host server1
 ServerAliveInterval 30
```

ServerAliveInterval 30表示ssh客户端每隔30秒给远程主机发送一个no-op包，no-op是无任何操作的意思，这样远程主机就不会关闭这个SSH会话。

为了使所有用户生效，你可以在/etc/ssh/ssh_config全局配置文件添加如下一行：

```	
ServerAliveInterval 30
```

还可以在连接时使用选项：

```
ssh -o ServerAliveInterval=30 user@remote-ssh-server-ip
```

# 出现的新笔记本安装ubuntu后无法搜索到wifi问题

很可能是网卡驱动的问题，首先查看网卡型号，然后确定内核是否支持当前无线网卡。然后安装对应的驱动。

# jupyter notebook如何使用

首先把ipython升级到版本4.0以后，切换到存储了ipynb的目录下，运行jupyter notebook就会在浏览器窗口列出ipynb文件和内容

# ubuntu下 vi输入方向键会变成ABCD

ubuntu下 vi输入方向键会变成ABCD，这是ubuntu预装的是vim tiny版本，安装vim full版本即可解决。

先卸载vim-tiny：

```
sudo apt-get remove vim-common
```

再安装vim full：

```
sudo apt-get install vim
```

# ubuntu操作系统"Failed to fetch"错误

```
W: Failed to fetch http://archive.ubuntu.com/ubuntu/dists/precise-updates/main/binary-i386/Packages  Something wicked happened resolving 'archive.ubuntu.com:http' (-5 - No address associated with hostname)
  
W: Failed to fetch http://archive.ubuntu.com/ubuntu/dists/precise-updates/restricted/binary-i386/Packages  Something wicked happened resolving 'archive.ubuntu.com:http' (-5 - No address associated with hostname)
```
解决这个问题十分简单，只要设置妥当DNS服务

sudo vi /etc/resolv.conf

比如

```
# Dynamic resolv.conf(5) file for glibc resolver(3) generated by resolvconf(8)
#     DO NOT EDIT THIS FILE BY HAND -- YOUR CHANGES WILL BE OVERWRITTEN
domain abc.com
search abc.com
nameserver 10.96.1.18
nameserver 10.96.1.19
```

为了防止每次重启都需要添加，可以修改 resolvconf服务的配置文件: /etc/resolvconf/resolv.conf.d/base ，这样在机器重启或 resolvconf 服务重启 都可以保证配置会写到/etc/resolv.conf 里面 

# 安装NVIDIA显卡后无法进入tty模式

编辑/etc/default/grub

修改GRUB_CMDLINE_LINUX_DEFAULT的值为nomodeset

更新grub：sudo update-grub

重启

# Ubuntu永久挂载硬盘分区

先查看所有硬盘

```
fdisk -l |grep '/dev'
```

然后挂载一个

```
sudo mount /dev/sdb  /data
```

但这种方法有个不好的地方是机器重启后又得手工重新挂载.

首先我们得到/dev/sdb这个分区的UUID,使用以下命令:

```
sudo blkid /dev/sdb
```

然后,我们按照/etc/fstab文件中的格式添加一行如下内容:

UUID=904C23B64C23964E /data ntfs defaults        0      2

其中第一列为UUID, 第二列为挂载目录（该目录必须为空目录），第三列为文件系统类型，第四列为参数，第五列0表示不备份，最后一列必须为２或0(除非引导分区为1)

# matplotlib后台设置画图出错

backend: agg in ~/.config/matplotlib'/matplotlibrc

'/etc/matplotlibrc' Then modify the backend in that file to backend : Agg. 

# ubuntu关闭端口

```
sudo lsof -i:6006
kill PID
```

# ubuntu查看文件夹大小

```
du -sh * | sort -nr | head 
```

# ubuntu 查看当前文件夹内的文件数

```
ls | wc -l
```

# 多GPU下设定程序可见设备

在终端执行前添加下面语句

```
CUDA_VISIBLE_DEVICES=0
```

或者在代码中添加如下语句

```
import os
os.environ["CUDA_DEVICE_ORDER"]="PCI_BUS_ID"
os.environ["CUDA_VISIBLE_DEVICES"]="0"
```

# linux下快速删除大量的文件

先安装rsync 

```
yum install rsync
```

新建一个空文件夹bk，清空target文件夹

```
rsync --delete-before -d bk/ target/
```

# linux安装HDF5, boost

```
#CentOS
yum -y install hdf5-devel

yum install boost boost-devel

#Ubuntu
sudo apt-get install libhdf5-dev

sudo apt-get install libboost-all-dev
```

# Linux下释放gpu显存

tensorflow有时候会由于某种原因，在关闭程序后，GPU的显存仍处于被占用的状态，而用nvidia-smi查不到对应的进程pid。这时释放显存的方法：

```
sudo fuser /dev/nvidia*
```

该命令会显示所有占用nvidia设备的进程pid，将这些pid逐个kill掉：

```
kill -9 pid
```

发现显存已经被释放。不过，造成这种显存不能被释放现象的原因尚不清楚。

# vim全文查找替换确认

```
:1,$s/str1/str2/gc

```

## 常见解压压缩命令

tar 
解包：tar xvf FileName.tar
打包：tar cvf FileName.tar DirName
（注：tar是打包，不是压缩！）

.gz
解压1：gunzip FileName.gz
解压2：gzip -d FileName.gz
压缩：gzip FileName
.tar.gz 和 .tgz
解压：tar zxvf FileName.tar.gz
压缩：tar zcvf FileName.tar.gz DirName

.bz2
解压1：bzip2 -d FileName.bz2
解压2：bunzip2 FileName.bz2
压缩： bzip2 -z FileName

.tar.bz2
解压：tar jxvf FileName.tar.bz2
压缩：tar jcvf FileName.tar.bz2 DirName

.bz
解压1：bzip2 -d FileName.bz
解压2：bunzip2 FileName.bz
压缩：未知
.tar.bz
解压：tar jxvf FileName.tar.bz
压缩：未知

.Z
解压：uncompress FileName.Z
压缩：compress FileName
.tar.Z
解压：tar Zxvf FileName.tar.Z
压缩：tar Zcvf FileName.tar.Z DirName
.zip
解压：unzip FileName.zip
压缩：zip FileName.zip DirName

.rar
解压：rar x FileName.rar
压缩：rar a FileName.rar DirName

# zstd 压缩解压缩

使用 Zstandard 压缩来压缩 / 解压文件. 更多信息：https://github.com/facebook/zstd.

将一个文件压缩到一个 .zst 后缀的压缩文件中:
zstd {{file}}

解压缩一个文件:
zstd -d {{file}}.zst

将文件解压缩到标准输出 (stdout):
zstd -dc {{file}}.zst

使用指定的压缩等级来压缩一个文件.0 = 最差，19 = 最好 （默认等级是 3):
zstd -{{level}} {{file}}

使用更多内存 （解压或压缩时） 来得到更高的压缩比:
zstd --ultra -{{level}} {{file}}

#创建python虚拟环境

1.安装virtualenv

```
pip install virtualenv
pip3 install virtualenv
```

2.创建虚拟环境

```
virtualenv envA
```

如果你当前的Python3/Scripts的查找路径在Python2/Scripts的前面，那么将会使用python3作为这个虚拟环境的解释器。如果python2/Scripts在python3/Scripts前面，那么将会使用Python2来作为这个虚拟环境的解释器。

3.进入环境

```
source envA/bin/activate
```

4.退出环境

```
deactivate
```

# github 设置代理

```
git config --global http.proxy 'socks5://127.0.0.1:1080'

git config --global https.proxy 'socks5://127.0.0.1:1080'
```

# linux解压大于4G的zip文件

unzip可能无法解压太大的zip文件，可以使用7za

https://sourceforge.net/projects/p7zip/files/p7zip/ 下载p7zip_16.02_src_all.tar.bz2

```
tar -xjpf   p7zip_16.02_src_all.tar.bz2
cd p7zip_16.02
make && make install
7za x XXX.zip
```

# gitlab权限问题

```
ssh-keygen -t rsa -C "zoujy2"

vi /root/.ssh/id_rsa.pub
```

将公钥添加到gitlab的SSH Keys里

# 远程拷贝忽略软连接的数据

```
rsync -avzPl
```

# ip摄像头解决获取帧延迟问题

需要设置摄像头缓存为1，避免读到缓存很多帧之前的数据

```
video_source = "rtsp://admin:leface2019@192.168.1.116:554"
gst_str = ('rtspsrc location={} latency=100 ! rtph265depay ! h265parse ! omxh265dec ! nvvidconv ! video/x-raw, width=(int)1920, height=(int)1080, format=(string)BGRx ! videoconvert !appsink max-buffers=1 drop=true').format(video_source)
vid = cv2.VideoCapture(gst_str,cv2.CAP_GSTREAMER)
```

# pip改国内源

```
pip install tensorflow -i https://pypi.douban.com/simple
```

# opencv读取实时帧

```
import queue,threading
import cv2

class VideoCapture:
    def __init__(self, name):
        self.cap = cv2.VideoCapture(name)
        self.q = queue.Queue()
        t = threading.Thread(target=self._reader)
        t.daemon = True
        t.start()

        # read frames as soon as they are available, keeping only most recent one
    def _reader(self):
        while True:
            ret, frame = self.cap.read()
            if not self.q.empty():
                try:
                    self.q.get_nowait()   # discard previous (unprocessed) frame
                except queue.Empty:
                    pass
            self.q.put([ret,frame])

    def read(self):
        return self.q.get()

    def release(self):
        self.cap.release()
		
cap = VideoCapture(name)
return_value, frame = cap.read()

```

# opencv mat存储顺序和内存排序

```
opencv按照C,W,H的顺序存储，在mat.data获取数据内存块的时候，也就是先存一个像素点的B,G,R值然后再按行依次存储每个像素点，最后按列存储像素点。

所以对于模型输入，当模型输入是NHWC时候,mat.data能直接作为指针地址拷贝给模型接口；当模型输入是NCHW时候需要先将mat分离通道然后再用mat的push_back放入一个新的mat来获取mat.data按W,H,C顺序存储像素点
```

# docker 快速使用命令

```
#从一个运行中的docker 创建新镜像
docker commit 7f09530c0738 tensorrt:master

#启动一个容器，不会exit就退出
nvidia-docker run -t -i -d tensorrt:master /bin/bash

#进入正在运行的docker
docker exec -it newdecode /bin/bash

# 拷贝
docker cp test.jpg newdecode:/root/TR/

#导出镜像
docker save -o tensorrt.tar tensorrt:master

#加载镜像
docker load -i tensorrt.tar

# docker访问出现Permission denied

临时关闭selinux：

setenforce 0

# export导出image
docker export -o trt8_export.tar 容器id
docker import trt8_export.tar test_trt8_export:v1
docker run -tid --gpus all --name trt8_export_test ffc91ac17602 /bin/bash
# 只能用上述方式起export的image否则会出现gpu失效问题

#查看和启动nvidia-docker
systemctl status nvidia-docker
systemctl start nvidia-docker
nvidia-docker run -t -i -d --shm-size=512g -v /dfsdata2/jinyi_data:/jinyi_data torch1.5.1-cuda10.1-cudnn7-devel:ddp /bin/bash

```

# 编译GPU版本得opencv

```
opencv4.0.0安装
cmake -D CMAKE_BUILD_TYPE=RELEAS -D CMAKE_INSTALL_PREFIX=/usr/local -D WITH_TBB=ON -D WITH_CUDA=ON -D BUILD_opencv_cudacodec=OFF -D BUILD_opencv_xfeatures2d=OFF -D OPENCV_PC_FILE_NAME=opencv.pc -D OPENCV_GENERATE_PKGCONFIG=YES -D WITH_V4L=ON -D WITH_GSTREAMER=ON -D OPENCV_EXTRA_MODULES_PATH=/home/lenovo/TR/opencv_contrib-4.0.0/modules -D PYTHON_EXECUTABLE=$(which python3) -D WITH_CUDNN=ON -D OPENCV_DNN_CUDA=ON -D CUDA_ARCH_BIN=7.5 ..
```

# vim删除不包含指定内容的行

```
g!/4107907252/d
```

# linux查找某个lib

```
find /usr -name "libnvcuvid*"
ldconfig -p | grep "libnvcuvid*"
```

# 关于opencv填边

```
cv::copyMakeBorder(resized_image, padding_image, _dh_a, _dh_b, _dw_a, _dw_b, cv::BORDER_CONSTANT, cv::Scalar(128,128,128));
cv::copyMakeBorder(resized_image, padding_image, _dh_a, _dh_b, _dw_a, _dw_b, cv::BORDER_CONSTANT, cv::Scalar(128));
```

注意这两种方式填边不一样，第一种方式为全部数值为128，第二种不是

# 批量结束进程

```
#结束所有包含main_jo的进程
ps -ef |grep main_jo |awk '{print $2}'|xargs kill -9
```

# 统计所有文件数量包括子文件夹内的

```
ls -lR| grep "^-" | wc -l
```

# 免密钥登录

```
#待登录机器生成密钥
ssh-keygen -t  rsa
#拷贝到另一台机器
ssh-copy-id -i ~/.ssh/id_rsa.pub root@10.110.129.105
实现待登录机器免密登录
```

# python opencv完全安装支持cuda

```
pip install --upgrade pip
pip install opencv-python -i https://pypi.douban.com/simple
pip install opencv-contrib-python -i https://pypi.douban.com/simple
pip install opencv-python-headless
```

# conda创建环境

```
conda create -n py36 python=3.6
activate env_name
deactivate env_name
#下载慢
conda config --add channels https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/free/
conda config --add channels https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/main/
conda config --set show_channel_urls yes
```

# onnx转trt

```
trtexec --onnx=DLA60xc_nhwc.onnx --fp16 --saveEngine=DLA60xc_nhwc.trt --explicitBatch --workspace=512

#动态batchsize
trtexec --explicitBatch --onnx=Yolov5s_nhwc_dynamic.onnx --minShapes=input:1x320x576x3 --optShapes=input:16x320x576x3 --maxShapes=input:32x320x576x3 --saveEngine=Yolov5s_nhwc_dynamic.trt --fp16 --workspace=1024

onnx2trt DLA60xc.onnx -o DLA60xc.trt -b 1 -d 16 -q
```

# linux创建用户

```
adduser jinyi
passwd jinyi
usermod -g root jinyi
chmod -v u+w  /etc/sudoers
添加
jinyi   ALL=(ALL)       NOPASSWD:ALL
chmod -v u-w  /etc/sudoers

sudo -i
root下sudo chmod 666 /var/run/docker.sock
```

# vim拷贝缩进问题

```
1. 在拷贝前输入:set paste (这样的话，vim就不会启动自动缩进，而只是纯拷贝粘贴）
2. 拷贝完成之后，输入:set nopaste (关闭paste)
```

# 快速拷贝大量小文件

```
#远程往本地pull
rsync --archive --partial --progress --compress root@10.110.110.112:/dfsdata/DATASET ./

#同步远程
rsync --archive --partial --progress --compress --delete SDv3 jinyi@10.110.157.140:/data/jinyi
```

# 改变数据用户权限

```
chown -R jinyi:jinyi DATASET/
```

# 查找文件内容

```
#当前目录下查找包含hello,world!的文件
grep -rn "hello,world!" *
```

# 当前目录拷贝前20个数据

```
ls | head -n 20 |xargs -i cp -r {} /dfs/data/
```

# 终端配置文件传输工具 sz,rz

```
yum install lrzsz
apt-get install lrzsz
```

# 将frame中连续帧图片压缩成视频

```
ffmpeg -f image2 -i frame/%05d.jpg -b 5000k -c:v mpeg4 result.mp4
```

# -bash: /bin/tar: Argument list too long

```
find ./baidu20w_encrypt/ -name "*" > file_list.txt
tar -cvz -T file_list.txt -f baidu20w_encrypt.tar
```

# 删除大量指定小文件，rm失败Argument list too long

```
进入文件夹目录
ls>file_list.txt

import os, shutil
f = open("file_list.txt",'r')
lines = f.readlines()
lines = [v.strip() for v in lines]

names = os.listdir("./")
for name in names:
    if name not in lines:
        print(name)
        shutil.rmtree(name)
```

# 随机多嵌套文件夹下拷贝少量数据

```
from shutil import copyfile
from os import walk
import random,os

soc_cover_path = '2022_2_23' #源文件路径

dst_cover_path = 'test'#目标文件路径

paths = []
for (dirpath, dirnames, filenames) in walk(soc_cover_path):
    for filename in filenames:
        paths.append(os.path.join(dirpath,filename))
random.shuffle(paths)
for path in paths[:20]:
    copyfile(path, os.path.join(dst_cover_path, path.split('/')[-1]))
```

# pytorch计算模型参数量

```
total_params = sum(param.numel() for param in model.parameters())
```

# L2归一化

```
#numpy
a = a / np.linalg.norm(a, axis=1, keepdims=True)
#pytorch
a = a / a.norm(dim=1, keepdim=True)
```

# 选视频与快速抽帧

```
#将视频放到文件夹下，可视化一帧选场景

import os
import cv2
names = os.listdir('videos')
ind=0
for name in names:
    cap=cv2.VideoCapture(os.path.join('videos',name))
    width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))
    height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))
    fps = cap.get(cv2.CAP_PROP_FPS)
    ret, frame = cap.read()
    print(width,height,fps)
    cv2.imwrite('{}.jpg'.format(ind),frame)
    ind+=1

#使用ffmpeg快速查看一帧	

ffmpeg -i D01_merge.mp4 -ss 1 -f image2 1.jpg

#使用ffmpeg每秒抽一帧高质量图像，将videos下视频抽帧保存至frame

import os
if not os.path.exists('frame'):
    os.makedirs('frame')
names = os.listdir('videos')
ind=0
for name in names:
    command = "ffmpeg -i {} -vf fps=1/1 -qscale:v 2 frame/frame_{}_%d.jpg".format(os.path.join("videos",name),ind)
    os.system(command)
    ind+=1
```

# conda

```
#创建指定conda python环境到指定目标
conda create -p /dfs/data/llm_env python=3.10

#显示所有conda环境
conda env list
conda activate /dfs/data/llm_env
conda install --prefix=/dfs/data/llm_env
```

# vim多行缩进

```
按Esc进去命令行模式

光标移动到开头，按shift+v，然后按上下方向键选择多行

按shift + < 向前移，按shift + > 向后移
```

# python管理子进程

```
import subprocess

#非阻塞形式，可以控制杀死
status = subprocess.Popen(["python3", "-m", "vllm.entrypoints.api_server", "--model", eval_model_path,\
                                      "--tensor-parallel-size", "1",\
                                      "--trust-remote-code",
                                      "--port", "8097"], shell=False)
status.kill()

#阻塞形式，必须等待完成
status = subprocess.call(["python3", "evalue.py", "--modelname", "Qwen2", \
                                                  "--temp", "0.8", \
                                                  "--noise_rate", "1.0", \
                                                  "--plm", eval_model_path, \
                                                  "--passage_num", "3", \
                                                  "--datasets", "en_refine", "zh_refine"], shell=False)																  
```

# 自动检测gpu空闲启动程序

```
import os
import time
GPU_ID=2


while True:
    gpu_free_ls = os.popen('nvidia-smi --query-gpu=memory.free --format=csv').readlines()[1:]
    print(gpu_free_ls)
    gpu_free = int(gpu_free_ls[GPU_ID].strip().split()[0])
    print('gpu_free:', gpu_free)
    
    if gpu_free > 20000:
        os.system(f'''python generate.py --temp 0.9''')
        ...  
        break
        
    # 暂停5分钟再进行下一次扫描
    time.sleep(60*5)
    print('sleeping...')
```

# 检测CUDA、cuDNN、Pytorch是否可用

```
import torch
print('CUDA版本:',torch.version.cuda)
print('Pytorch版本:',torch.__version__)
print('显卡是否可用:','可用' if(torch.cuda.is_available()) else '不可用')
print('显卡数量:',torch.cuda.device_count())
print('是否支持BF16数字格式:','支持' if (torch.cuda.is_bf16_supported()) else '不支持')
print('当前显卡型号:',torch.cuda.get_device_name())
print('当前显卡的CUDA算力:',torch.cuda.get_device_capability())
print('当前显卡的总显存:',torch.cuda.get_device_properties(0).total_memory/1024/1024/1024,'GB')
print('是否支持TensorCore:','支持' if (torch.cuda.get_device_properties(0).major >= 7) else '不支持')
print('当前显卡的显存使用率:',torch.cuda.memory_allocated(0)/torch.cuda.get_device_properties(0).total_memory*100,'%')
```